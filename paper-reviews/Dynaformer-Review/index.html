<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>The review is done with the following paper:<br> <a href="https://www.sciencedirect.com/science/article/pii/S0306261923005937" rel="external nofollow noopener" target="_blank">Luca Biggio, Tommaso Bendinelli, Cheta Kulkarni, and Olga Fink. “Dynaformer: A Deep Learning Model for Ageing-aware Battery Discharge Prediction,” <em>Applied Energy</em>, 2023.</a></p> <h2 id="table-of-contents">Table of Contents</h2> <ul> <li><a href="#abstract">Abstract</a></li> <li> <a href="#background">Background</a> <ul> <li><a href="#battery">Battery</a></li> <li><a href="#transformer">Transformer</a></li> </ul> </li> <li> <a href="#model-architecture">Model Architecture</a> <ul> <li><a href="#embedding">Embedding</a></li> <li><a href="#encoder">Encoder</a></li> <li><a href="#decoder">Decoder</a></li> </ul> </li> <li> <a href="#results">Results</a> <ul> <li><a href="#experimental-setup">Experimental Setup</a></li> <li><a href="#performance-evaluation">Performance Evaluation</a></li> </ul> </li> <li><a href="#conclusion">Conclusion</a></li> </ul> <h2 id="abstract">Abstract</h2> <p>The main purpose of the paper is to propose a novel deep learning architecture which can be applied to batteries, namely <strong>Dynaformer</strong>. The model, Dynaformer, is a Transformer-based <a href="#2">[2]</a> model and outputs an EoD (end of discharge) prediction, given some context current and voltage curves.</p> <p>Dynaformer is able to infer the ageing state from a limited samples and predict the full voltage discharge curve, EoD, simultaneously.</p> <h2 id="background">Background</h2> <h3 id="battery">Battery</h3> <p>The following <em>Figure 1.</em> represents how batteries’ voltage curves look like based on the given input current profiles. When given constant current, it forms a continuous curve as the graph on the far left. On the other hand, when given some variable current profiles with multiple transitions, the graphs differ from the other corresponding to the altering current.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig1-1400.webp"></source> <img src="/assets/img/dynaformer/fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p align="center"> <i>Figure 1.</i> Varying voltage curves corresponding to altering current profiles <a href="#1">[1]</a> </p> <p>There are two main categories of solving EoD prediction and ageing inference: model-based method and data-driven method. The first method, model-based method, mainly focuses on representation of battery’s physical internal mechanism. By constructing an ideal model of the battery, it has a good performance. However, due to it’s complex representation of the model, it is computationally expensive and is not an easy work to design the model precisely.<br> The second method, data-driven method, is to predict EoD and ageing inference using a huge amount of battery data. It is easier to model the system compared to the model-based method since it requires minimum prior knowledge on the battery’s discharge and degradation processes. Nevertheless, it also has some disadvantages. It requires large labeled training dataset and it is inefficient to train with such long time series data.</p> <h3 id="transformer">Transformer</h3> <p>It is essential to understand how <strong>Transformer</strong> <a href="#2">[2]</a> works in order to understand the Dynaformer. Let’s consider the following sentence.</p> <p align="center"> <b>The dog</b> is playing and <b>she</b> likes playing with <b>me</b>. </p> <p>We know that <b>she</b> is indicating <b>the dog</b>, not <b>me</b>. Transformer is all about understanding the context and the hidden meaning behind the given data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig2-1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig2-1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig2-1-1400.webp"></source> <img src="/assets/img/dynaformer/fig2-1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig2-2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig2-2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig2-2-1400.webp"></source> <img src="/assets/img/dynaformer/fig2-2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig2-3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig2-3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig2-3-1400.webp"></source> <img src="/assets/img/dynaformer/fig2-3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p align="center"> <i>Figure 2.</i> Transformer model architecture <a href="#2">[2]</a>. (Left) Embedding (Centre) (Right) </p> <h2 id="model-architecture">Model Architecture</h2> <h3 id="embedding">Embedding</h3> <h3 id="encoder">Encoder</h3> <h3 id="decoder">Decoder</h3> <h2 id="results">Results</h2> <h3 id="experimental-setup">Experimental Setup</h3> <h3 id="performance-evaluation">Performance Evaluation</h3> <h2 id="conclusion">Conclusion</h2> <h2 id="reference">Reference</h2> <p><a id="1" href="https://www.sciencedirect.com/science/article/pii/S0306261923005937" rel="external nofollow noopener" target="_blank">[1]</a> Luca Biggio, Tommaso Bendinelli, Cheta Kulkarni, and Olga Fink. “Dynaformer: A Deep Learning Model for Ageing-aware Battery Discharge Prediction,” <i> <em>Applied Energy</em></i> 2023.</p> <p><a id="2" href="https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" rel="external nofollow noopener" target="_blank">[2]</a> Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention is All you Need,” <i>Advances in Neural Information Processing Systems 30 (NIPS 2017)</i>, 2017.</p> <p><a id="3" href="https://nasa.github.io/progpy/index.html" rel="external nofollow noopener" target="_blank">[3]</a> Chris Teubert, Katelyn Jarvis, Matteo Corbetta, Chetan Kulkarni, Portia Banerjee, Jason Watkins, and Matthew Daigle, “ProgPy Python Prognostics Packages,” v1.6, Oct 2023. URL <a href="https://nasa.github.io/progpy/index.html" rel="external nofollow noopener" target="_blank">https://nasa.github.io/progpy/index.html</a></p> <p><a id="4" href="https://www.nasa.gov/intelligent-systems-division/discovery-and-systems-health/pcoe/pcoe-data-set-repository/" rel="external nofollow noopener" target="_blank">[4]</a> B. Saha and K. Goebel (2007). “Battery Data Set”, NASA Prognostics Data Repository, NASA Ames Research Center, Moffett Field, CA.</p> <p><a id="5" href="https://link.springer.com/chapter/10.1007/978-3-030-32381-3_16" rel="external nofollow noopener" target="_blank">[5]</a> Sun, Chi, Xipeng Qiu, Yige Xu, and Xuanjing Huang. “How to fine-tune bert for text classification?.” In <i>Chinese Computational Linguistics: 18th China National Conference, CCL 2019, Kunming, China, October 18–20, 2019, Proceedings 18</i>, pp. 194-206. Springer International Publishing, 2019.</p> <p><a id="6" href="https://arxiv.org/abs/2010.11929" rel="external nofollow noopener" target="_blank">[6]</a> Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani et al. “An image is worth 16x16 words: Transformers for image recognition at scale.” <i>arXiv preprint arXiv:2010.11929</i> (2020).</p> </body></html>
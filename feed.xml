<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://3seoksw.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://3seoksw.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-11T23:32:38+00:00</updated><id>https://3seoksw.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Downlink Non-Orthogonal Multiple Access (NOMA)</title><link href="https://3seoksw.github.io/blog/2025/NOMA-background/" rel="alternate" type="text/html" title="Downlink Non-Orthogonal Multiple Access (NOMA)"/><published>2025-09-10T00:00:00+00:00</published><updated>2025-09-10T00:00:00+00:00</updated><id>https://3seoksw.github.io/blog/2025/NOMA-background</id><content type="html" xml:base="https://3seoksw.github.io/blog/2025/NOMA-background/"><![CDATA[<h2 id="background-of-downlink-networking-systems">Background of Downlink Networking Systems</h2> <p>In a downlink networking system, the base station (BS) is the one who manages and allocates resources to users. These resources typically include frequency bands, transmission power, time slots, and other related parameters. So a key aspect for BS to consider is efficient way of utilizing networking resources. In other words, since networking resources are limited, it is important to manage these resources efficiently to ensure high throughput data transmission.</p> <p>While there are multiple networking techniques to handle resources, in this page we’ll be briefly discussing the <strong>Non-Orthogonal Multiple Access (NOMA)</strong>. And it is essential to know what <strong>Orthogonal Multiple Access (OMA)</strong> is.</p> <h3 id="orthogonal-multiple-access-oma">Orthogonal Multiple Access (OMA)</h3> <p>OMA is a wireless communication technique where the communication resources are allocated orthogonally to users. What <em>“orthogonal”</em> resource allocation means is that resources such as frequency, power, or time are assigned exclusively to users, in order to prevent interference between the users.</p> <div class="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/NOMA/OMA-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/NOMA/OMA-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/NOMA/OMA-1400.webp"/> <img src="/assets/img/NOMA/OMA.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p align="center"> <i>Figure 1.</i> OMA Basic </p> <h3 id="non-orthogonal-multiple-access-noma">Non-Orthogonal Multiple Access (NOMA)</h3> <p>And the <strong>Non-Orthogonal Multiple Access (NOMA)</strong> is a more advanced which enhances spectral efficiency. It allows multiple users to share the same frequency band and time slots simultaneously. The key difference between NOMA and OMA lies here: instead of separating users orthogonally, NOMA differentiates users in power level. It assigns different power to users based on their channel condition, such as distance between user and BS or noise ratio.</p> <p>Let’s take a look at the following example, shown in <em>Figure 2</em>.</p> <div class="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/NOMA/NOMA-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/NOMA/NOMA-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/NOMA/NOMA-1400.webp"/> <img src="/assets/img/NOMA/NOMA.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p align="center"> <i>Figure 2.</i> NOMA Basic </p> <p>Suppose there are two users, <em>User 1</em> and <em>User 2</em>. The distance between the BS and the users differs, such that <em>User 1</em> is farther while <em>User 2</em> is closer.</p> <p>Since <em>User 1</em> is farther from the base station than <em>User 2</em>, it is likely that <em>User 1</em>’s signal will be more affected by noise. Due to this, the receiver may not be able to successfully decode User 1’s data. Therefore, the BS’s job is to assign more transmission power to <em>User 1</em> than to <em>User 2</em>. This power allocation ensures successful transmission of weaker users’ data, such as <em>User 1</em>’s, even under poor channel conditions.</p> <p>From the weaker user’s perspective, in this case <em>User 1</em> the decoding process is quite simple. Since <em>User 1</em>’s signal dominates, in terms of power, the received data can be directly decoded by treating <em>User 2</em>’s lower-power signal as noise.</p> <p>On the other hand, for stronger users, <em>User 2</em>, the receiver cannot tell the difference between the users within the same frequency band. o enable the stronger user’s receiver to distinguish between signals between <em>User 1</em> and <em>User 2</em>, <strong>Successive Interference Cancellation (SIC)</strong> is employed, which works by leveraging the difference in received power levels. What SIC essentially does is subtracting the weaker user’s signal from the received data. After cancellation, the receiver can decode its own signal.</p> <h2 id="basic-notations">Basic Notations</h2> <ul> <li>\(n\)th user</li> <li>\(k\)th channel</li> <li>\(N_k\): total number of users using \(k\)th channel</li> <li>\(z^k_n\): additive white Gaussian noise (AWGN)</li> <li>\(B_{total}\): total bandwidth</li> <li>\(K\): total number of channels</li> <li>\(N\): total number of users</li> <li>\(B_c=B_{total}/K\): divided bandwidth by channels</li> </ul> <h3 id="channel-to-noise-ratio-cnr">Channel to Noise Ratio (CNR)</h3> <p>CNR is a ratio between the power of the carrier signal (channel) and the power of the noise.</p> \[\begin{align} \Gamma_n^k &amp;= g^o_{n, k} \\ &amp;= \frac{|h^k_n|^2}{\sigma^2_{z_k}} \\ \end{align}\] <ul> <li>\(h^k_n\): channel response between BS and \(n\)th user which considers both the path loss \(\mathcal{P}_L\) and shadowing effect \(h'_{n, k}\) (= Rayleigh fading)</li> <li>\(\sigma^2_{z_k}\): variance of AWGN</li> </ul> <h3 id="signal-to-noise-plus-interference-ratio-sinr">Signal to Noise plus Interference Ratio (SINR)</h3> <blockquote> <p><strong>NOTE</strong>: An assumption behind the following equations is;</p> \[\Gamma^k_1 &gt; ... &gt; \Gamma^k_n &gt; ... &gt; \Gamma^k_{N_k}.\] <p>This means that the 1st user and the last user has the strongest and lowest signal power respectively. According to NOMA protocol, users with lower CNR will be assigned with more power.</p> \[p^k_1 &lt; p^k_2 &lt; ... &lt; p^k_n &lt; ... &lt; p^k_{N_k},\] <p>where \(p^k_n\) denotes transmit power of user \(n\) using channel \(k\).</p> <p>Due to the characteristic of successive interference cancellation (SIC), an user will treat less power as an interference and decode signals of more power.</p> </blockquote> \[\begin{align} \gamma_{n}^{k} &amp;= \frac{p_n^k \Gamma_n^k}{1 + \sum_i^{n-1}{p_i^k \Gamma_n^k}} \\ &amp;= \frac{P_{n, k}(t) \mathcal{P}_L(d)|h'_{n, k(t)}|^2}{n^2_0 + \sum_{i=1}^{n-1}{P_{n, k}(t) \mathcal{P}_L(d)|h'_{n, k(t)}|^2}} \end{align}\] <ul> <li>\(d\): distance between BS and user \(n\) which is using channel \(k\)</li> <li>Typically, \(n^2_0\) and \(1\) represents a constant noise term.</li> <li>Equation (2) is from <code class="language-plaintext highlighter-rouge">TPPD</code> paper.</li> </ul> <p>Overall, SINR is to calculate the ratio between received power (numerator) and other noises and interferences (denominator) which comprises noises (1 or \(n^2_0\)) and interferences (sum of other users’ received power).</p> <p>Take the numerator, by multiplying the allocated power and CNR (\(p^k_n \Gamma^k_n\)), this results a signal power considering the noise.</p> <p>And now let’s take a look at the denominator. The 1 denotes the noise and \(\sum_i^{n-1}p^k_i\Gamma^k_n\) is to sum all the signal powers which are less than \(p^k_n\) (take a look at the <strong>NOTE</strong> assumption).</p> <p>By dividing the above two, ratio of signal power versus noises can be calculated.</p> <h3 id="data-rate">Data Rate</h3> \[R^k_n(\Gamma^k_n, p^k_1, ..., p^k_n) = B_c\log_2{(1+\frac{p^k_n \Gamma^k_n}{1+\sum_{i=1}^{n-1}p^k_i\Gamma^k_n})}.\] <ul> <li>\(\frac{p^k_n \Gamma^k_n}{1+\sum_{i=1}^{n-1}p^k_i\Gamma^k_n}\): As described above, this term represents SINR.</li> <li>\(1 + \frac{p^k_n \Gamma^k_n}{1+\sum_{i=1}^{n-1}p^k_i\Gamma^k_n}\): By adding 1 to SINR, it can prevent logarithm taking zero.</li> <li>\(\log_2{(1+\frac{p^k_n \Gamma^k_n}{1+\sum_{i=1}^{n-1}p^k_i\Gamma^k_n})}\): The term calculates the achievable data rate for a noisy channel and it’s derived from Shannon capacity formula.</li> <li>\(B_c\log_2{(1+\frac{p^k_n \Gamma^k_n}{1+\sum_{i=1}^{n-1}p^k_i\Gamma^k_n})}\): Shannon capacity formula, providing an upper bound on the achievable data rate for a given channel. By multiplying the bandwidth (Hz) and achievable data rate, data rate for the given bandwidth is calculated.</li> </ul> <p>According to the above, two users’ data rate can be derived as such:</p> \[\begin{align} R^k_1(\Gamma^k_1, p^k_1, p^k_2) &amp;= B_c\log_2{(1+p^k_1\Gamma^k_1)} \\ R^k_2(\Gamma^k_2, p^k_1, p^k_2) &amp;= B_c\log_2{(1+ \frac{p^k_2\Gamma^k_2}{1+p^k_1\Gamma^k_2})}. \end{align}\] <h2 id="maximizing-sum-rate-msr">Maximizing Sum Rate (MSR)</h2> <p>Let \(A^k_n=2^{\frac{(R^k_n)_{min}}{B_c}}\) and assume \(A^k_2\geq 2.\)</p> <blockquote> <p>Derivation of \(A^k_n\): Let us assume there is a power \(p'\) which ends up with a minimum data rate \((R^k_n)_{min}\).</p> \[\begin{align*} (R^k_n)_{min} \triangleq B_c\log_2{(1 + \frac{p'\Gamma^k_n}{1+\sum^{n-1}_{i=1}p'\Gamma^k_n})} \end{align*}\] <p>For the sake of simplicity, let’s say the term inside the logarithm as \(P'\), achievable minimum data rate. Then the above equation can be rewritten as</p> \[2^{\frac{(R^k_n)_{min}}{B_c}}=P'=A^k_n.\] <p>MSR is an objective function to ensure the total throughput to be maximized; you can easily consider the MSR metric when the \(\alpha\)-fairness function is in the condition of \(\alpha=1\).</p> </blockquote> <p>For MSR, the power allocation problem is formulated as</p> \[\begin{align} \max_{P} &amp;\sum_{k=1}^{K}[R^k_1(p^k_1, p^k_2) + R^k_2(p^k_1, p^k_2)], \\ \text{subject to } &amp; R^k_n \geq (R^k_n)_{min}, n=1, 2, \forall k = 1, ..., K, \\ &amp; \sum_{k=1}^K(p^k_1 + p^k_2)\leq P_T, \\ &amp; 0 \leq p^k_1\leq p^k_2, \forall k=1, ..., K. \end{align}\] <p>As MSR the term itself describes, the problem is to maximize the sum rate, in other words data rate. MSR’s final objective is to find an optimal power for user 1 and 2.</p> <p>Here, let’s say there is a power limit of \(q_k=p^k_1+p^k_2\), meaning that total allocated power of \(k\)th channel should be \(q_k\). Then the solution for the MSR is</p> \[\begin{align} p^k_1 &amp;= \frac{q_k\Gamma^k_2 - A^k_2 + 1}{A^k_2\Gamma^k_2} \\ p^k_2 &amp;= q_k-p^k_1. \end{align}\] <h2 id="maximizing-minimal-rate-mmr">Maximizing Minimal Rate (MMR)</h2> \[\begin{align} p^k_1 &amp;= \frac{-(\Gamma^k_1 + \Gamma^k_2) + \sqrt{(\Gamma^k_1 + \Gamma^k_2)^2 + 4\Gamma^k_1(\Gamma^k_2)^2q_k}} {2\Gamma^k_1\Gamma^k_2} \\ p^k_2 &amp;= q_k - p^k_1 \end{align}\]]]></content><author><name></name></author><category term="background"/><category term="communications"/><summary type="html"><![CDATA[Basic Theoretical Background of Downlink NOMA system]]></summary></entry><entry><title type="html">Setting Up a Virtual Environment with Conda</title><link href="https://3seoksw.github.io/blog/2024/conda/" rel="alternate" type="text/html" title="Setting Up a Virtual Environment with Conda"/><published>2024-09-03T00:00:00+00:00</published><updated>2024-09-03T00:00:00+00:00</updated><id>https://3seoksw.github.io/blog/2024/conda</id><content type="html" xml:base="https://3seoksw.github.io/blog/2024/conda/"><![CDATA[<p>From the <a href="https://3seoksw.github.io/blog/2024/venv/">previous post</a>, we’ve seen how to set up a virtual environment with Python’s <a href="https://docs.python.org/3/library/venv.html"><code class="language-plaintext highlighter-rouge">venv</code></a>. In this post, we will be taking a look at how to set up a Python developing environment with <a href="https://docs.anaconda.com/"><code class="language-plaintext highlighter-rouge">conda</code></a> when you’re dealing with complex environments. The <code class="language-plaintext highlighter-rouge">venv</code> is great enough when you’re developing a simple program or web application, in my opinion. However, if you’re trying to develop data science-related things, AI models, or such, I believe it is much easier to use <code class="language-plaintext highlighter-rouge">conda</code>, since <code class="language-plaintext highlighter-rouge">conda</code> is able to create multiple Python environments with specific Python versions.</p> <p>You can either install <code class="language-plaintext highlighter-rouge">anaconda</code> or <code class="language-plaintext highlighter-rouge">miniconda</code> (both are <code class="language-plaintext highlighter-rouge">conda</code>) based on your preference. I am using <a href="https://docs.anaconda.com/miniconda/#"><code class="language-plaintext highlighter-rouge">miniconda</code></a> since it’s much lighter than the <code class="language-plaintext highlighter-rouge">anaconda</code>. Either way, it works the same way, the only difference between those two is just <code class="language-plaintext highlighter-rouge">anaconda</code> comes with various pre-installed packages so it might be a little bulky.</p> <hr/> <h3 id="installation">Installation</h3> <p>This <a href="https://docs.anaconda.com/miniconda/#quick-command-line-install">page</a> shows how to install <code class="language-plaintext highlighter-rouge">miniconda</code> with command line scripts.</p> <p>After the installation, every command will start with <code class="language-plaintext highlighter-rouge">conda</code>. When <code class="language-plaintext highlighter-rouge">conda</code> command not found is displayed, make sure to add environment variable into your <code class="language-plaintext highlighter-rouge">.zshrc</code> or <code class="language-plaintext highlighter-rouge">.bashrc</code> file.</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># ~/.zshrc (or .bashrc)</span>
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$HOME</span><span class="s2">/miniconda3/bin:</span><span class="nv">$PATH</span><span class="s2">"</span>
</code></pre></div></div> <p>If the terminal displays <code class="language-plaintext highlighter-rouge">(base)</code>, you’re all set.</p> <h3 id="creating-a-new-virtual-environment">Creating a new virtual environment</h3> <p>You can simply create a new <code class="language-plaintext highlighter-rouge">conda</code> environment with the following command.</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create <span class="nt">--name</span> &lt;env-name&gt; <span class="nv">python</span><span class="o">=</span>&lt;version&gt;
</code></pre></div></div> <h3 id="activating">Activating</h3> <p>After creating a new virtual environment, you can activate the one as follows:</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda activate &lt;env-name&gt;
</code></pre></div></div> <p>Then, the name of the virtual environment from the terminal will change from <code class="language-plaintext highlighter-rouge">(base)</code> to <code class="language-plaintext highlighter-rouge">(env-name)</code>.</p> <p>To verify whether the environment is reall ready, try <code class="language-plaintext highlighter-rouge">which python</code> and see if the result is something like <code class="language-plaintext highlighter-rouge">~/miniconda3/envs/&lt;env-name&gt;/bin/python</code>.</p> <h3 id="installing-packages">Installing packages</h3> <p>It is always a good practice to use <code class="language-plaintext highlighter-rouge">requirements.txt</code> file. As described from the <a href="https://3seoksw.github.io/blog/2024/venv/">previous post</a>, using <code class="language-plaintext highlighter-rouge">pip-tools</code> will make your life much easier.</p> <p>From this step, you can follow the steps of <a href="https://3seoksw.github.io/blog/2024/venv/#installing-packages">last post’s package installation steps</a>.</p>]]></content><author><name></name></author><category term="etc"/><category term="python,"/><category term="dev-tools"/><summary type="html"><![CDATA[How to set up a stable venv with Conda]]></summary></entry><entry><title type="html">Setting Up a Virtual Environment in Python</title><link href="https://3seoksw.github.io/blog/2024/venv/" rel="alternate" type="text/html" title="Setting Up a Virtual Environment in Python"/><published>2024-08-29T00:00:00+00:00</published><updated>2024-08-29T00:00:00+00:00</updated><id>https://3seoksw.github.io/blog/2024/venv</id><content type="html" xml:base="https://3seoksw.github.io/blog/2024/venv/"><![CDATA[<p>Nowadays, there are so many stable ways to program with Python; you can use either use cloud services (such as <a href="https://colab.research.google.com/">colab</a> or <a href="https://jupyter.org/">jupyter notebook</a>) or you can simply install python globally into your local machine.</p> <p>But, when you’re dealing with bunch of different Python projects, it is critical to be careful with the package dependencies. In order to address such issue, virtual environment is used and it boosts up the stability. Virtual environment allows you to create multiple separate Python environments into your local machine and this enables you to install separate Python packages (or libraries) per virtual environment.</p> <p>As far as I know, there are two popular ways to manage virtual environment, which are <a href="https://docs.anaconda.com/"><code class="language-plaintext highlighter-rouge">anaconda</code></a> (or so called <code class="language-plaintext highlighter-rouge">conda</code>) and Python’s <a href="https://docs.python.org/3/library/venv.html"><code class="language-plaintext highlighter-rouge">venv</code></a>. You can take a look at those two and choose as your preference. The <code class="language-plaintext highlighter-rouge">venv</code> which is a Python-provided way is capable of managing packages with light-weight but it cannot manage multiple environments with multiple Python versions. Since using the <code class="language-plaintext highlighter-rouge">venv</code> is much easier and simple than the <code class="language-plaintext highlighter-rouge">conda</code>, this post will be dealing with the <code class="language-plaintext highlighter-rouge">venv</code> only. For more information about how to setup a <code class="language-plaintext highlighter-rouge">conda</code> environment, take look at the <a href="https://3seoksw.github.io/blog/2024/conda/">this post</a>.</p> <hr/> <h3 id="pythons-venv">Python’s <code class="language-plaintext highlighter-rouge">venv</code></h3> <p>Fist off, let’s create a directory for virtual environments under home directory.</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> ~/venvs
</code></pre></div></div> <p>Then you can create a new virtual environment into the <code class="language-plaintext highlighter-rouge">~/venvs</code> directory by running the following command:</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> venv ~/venvs/&lt;your-venv&gt;
</code></pre></div></div> <p>And to activate the created virtual environment, run the following commands and verify whether it has been activated.</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">source</span> ~/venvs/&lt;your-venv&gt;/bin/activate
which python
</code></pre></div></div> <p>By running the <code class="language-plaintext highlighter-rouge">which</code> command, you will be able to see something like <code class="language-plaintext highlighter-rouge">~/venvs/&lt;your-venv&gt;/bin/python</code>. If you are not able to see such result, make sure the venv is actually created.</p> <p>You can simple deactivate the <code class="language-plaintext highlighter-rouge">venv</code> by running</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>deactivate
</code></pre></div></div> <h3 id="installing-packages">Installing Packages</h3> <p>Now that we create and activated the <code class="language-plaintext highlighter-rouge">venv</code>, we’re ready to install Python packages. Of course, you can simply run <code class="language-plaintext highlighter-rouge">pip install</code> but if the packages required for the project are too many, the dependencies between packages matter. There it is much easier to manage packages with file.</p> <p>Create a simple text file (<em>e.g.</em> <code class="language-plaintext highlighter-rouge">requirements.in</code>) containing the packages you need as such:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>numpy
pandas
pip-tools
</code></pre></div></div> <p>I will be using <a href="https://github.com/jazzband/pip-tools/"><code class="language-plaintext highlighter-rouge">pip-tools</code></a> so run the following command to install <code class="language-plaintext highlighter-rouge">pip-tools</code>.</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>pip-tools
</code></pre></div></div> <p>Now, by using the <code class="language-plaintext highlighter-rouge">pip-tools</code>, you will be able to regenerate <code class="language-plaintext highlighter-rouge">requirements.txt</code> which contains each package’s version dependencies automatically. After that, you will be able to see that <code class="language-plaintext highlighter-rouge">requirements.txt</code> file is containing packages with versions. And, you can install the packages with ease by running the following!</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip-compile <span class="nt">--output-file</span><span class="o">=</span>requirements.txt requirements.in
pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div> <p>If you would like to add new package(s) to your <code class="language-plaintext highlighter-rouge">venv</code>, you can add package(s) into <code class="language-plaintext highlighter-rouge">requirements.in</code> file and upgrade the dependencies.</p> <div class="language-zsh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip-compile <span class="nt">--output-file</span><span class="o">=</span>requirements.dev.txt requirements.dev.in <span class="nt">--upgrade</span>
pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div>]]></content><author><name></name></author><category term="etc"/><category term="python,"/><category term="dev-tools"/><summary type="html"><![CDATA[How to set up a stable venv in python]]></summary></entry><entry><title type="html">Pearson Correlation Coefficient (PCC)</title><link href="https://3seoksw.github.io/blog/2024/PCC/" rel="alternate" type="text/html" title="Pearson Correlation Coefficient (PCC)"/><published>2024-02-19T01:30:00+00:00</published><updated>2024-02-19T01:30:00+00:00</updated><id>https://3seoksw.github.io/blog/2024/PCC</id><content type="html" xml:base="https://3seoksw.github.io/blog/2024/PCC/"><![CDATA[<p><strong>Pearson Correlation Coefficient (PCC)</strong> is a statistic method of measuring linear correlation between two sets of data.</p> <hr/> <h3 id="definition">Definition</h3> <p>Say \(r_{xy}\) is representing a PCC between two variables, \(x\) and \(y\). Then, \(r_{xy}\) is defined as:</p> \[r_{xy} = \frac{\sum_{i=1}^{n}{(x_i - \bar{x})(y_i - \bar{y})}}{\sqrt{\sum_{i=1}^{n}{(x_i - \bar{x})^2}}\sqrt{\sum_{i=1}^{n}{(y_i - \bar{y})^2}}}\] <p>where $n$ is sample size, \(x_i, y_i\) are the samples with the index number of \(i\), \(\bar{x}\) is the sample mean and analogously for \(\bar{y}\). The \(r_{xy}\) is in the range of \([-1, 1]\). As the value gets closer to 1, it represents a strong linear correlation. And conversely when it gets near to -1, it means the two are inversely proportional. Finally, if it is 0, then there is no correlation.</p> <p>The above equation can also be expressed as follows:</p> \[r_{xy} = \frac{cov(x, y)}{\sigma_x \sigma_y}\] <p>where \(cov\) is covariance, and \(\sigma\) is standard deviation.</p>]]></content><author><name></name></author><category term="concepts"/><category term="statistics"/><summary type="html"><![CDATA[Statistic method of measuring linear correlation]]></summary></entry><entry><title type="html">Markov Decision Processes</title><link href="https://3seoksw.github.io/blog/2023/MDP/" rel="alternate" type="text/html" title="Markov Decision Processes"/><published>2023-12-27T00:00:00+00:00</published><updated>2023-12-27T00:00:00+00:00</updated><id>https://3seoksw.github.io/blog/2023/MDP</id><content type="html" xml:base="https://3seoksw.github.io/blog/2023/MDP/"><![CDATA[<h1 id="markov-decision-processes">Markov Decision Processes</h1> <h2 id="1-markov-processes">1. Markov Processes</h2> <h3 id="11-introduction-to-mdps">1.1. Introduction to MDPs</h3> <ul> <li><em>Markov Decision Processes</em> formally describe an environment for reinforcement learning.</li> <li>environment is fully observable</li> </ul> <h3 id="12-markov-property">1.2. Markov Property</h3> <ul> <li>the future is independent of the past given the present</li> </ul> <blockquote> <p><strong>Definition</strong><br/> A state \(S_t\) is <em>Markov</em> if and only if \(\mathbb{P}[S_{t+1}|S_t] = \mathbb{P}[S_{t+1}|S_1, ..., S_t]\)</p> </blockquote> <h3 id="13-markov-chains">1.3. Markov Chains</h3> <blockquote> <p><strong>Definition</strong><br/> A <em>Markov Process</em> (or <em>Markov Chain</em>) is tuple \((\mathcal{S}, \mathcal{P})\) \(\mathcal{S}\) is a finite set of states \(\mathcal{P}\) is a state transition probability matrix</p> </blockquote> <h2 id="2-markov-reward-processes">2. Markov Reward Processes</h2> <h3 id="21-markov-reward-process">2.1. Markov Reward Process</h3> <blockquote> <p><strong>Definition</strong><br/> A <em>Markov Reward Process</em> is a tuple \((\mathcal{S}, \mathcal{P}, \mathcal{R}, \mathcal{\gamma})\)</p> </blockquote> <h3 id="22-return">2.2. Return</h3> <blockquote> <p><strong>Definition</strong><br/> \(G_t = R_{t+1} + \gamma R_{t+2} + ... = \sum_{k=0}^{\infty}\gamma^k R_{t+k+1}\) where \(\gamma \in [0, 1]\).</p> </blockquote> <h3 id="23-value-function">2.3. Value Function</h3> <blockquote> <p><strong>Definition</strong><br/> \(v(s) = \mathbb{E}[G_t |S_t = s]\) <em>e.g.)</em> \(G_1 = R_2 + \gamma R_3 + ... + \gamma^{T-2}R_T\)</p> </blockquote> <h3 id="24-bellman-equation-for-mrps">2.4. Bellman Equation for MRPs</h3> \[\begin{align*} v(s) &amp;= \mathbb{E}[G_t | S_t = s] \\ &amp;= \mathbb{E}[R_{t+1} + \gamma R_{t+2} + \gamma^{2} R_{t+3} + ... | S_t = s] \\ &amp;= \mathbb{E}[R_{t+1} + \gamma(R_{t+2} + \gamma R_{t+3} + ...) | S_t = s] \\ &amp;= \mathbb{E}[R_{t+1} + \gamma(G_{t+1}) | S_t = s] \\ &amp;= \mathbb{E}[R_{t+1} + \gamma(v(S_{t+1})) | S_t = s] \\ \end{align*}\] <p align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mdp/value-function-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mdp/value-function-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mdp/value-function-1400.webp"/> <img src="/assets/img/mdp/value-function.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </p> \[v(s) = \mathcal{R}_s + \gamma\sum_{s'\in S}\mathcal{P}_{ss'}v(s')\] <h2 id="3-markov-decision-processes">3. Markov Decision Processes</h2> <h3 id="31-markov-decision-process">3.1. Markov Decision Process</h3> <blockquote> <p><strong>Definition</strong><br/> A <em>Markov Decision Process</em> is a tuple \((\mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}, \gamma)\)</p> </blockquote> <h3 id="32-policies">3.2. Policies</h3> <blockquote> <p><strong>Definition</strong><br/> \(\pi(a|s) = \mathbb{P}[A_t = a | S_t = s]\)</p> </blockquote> <h3 id="33-value-function">3.3. Value Function</h3> <blockquote> <p><strong>Definition</strong><br/> <em>state-value function</em><br/> \(v_\pi (s) = \mathbb{E}[G_t | S_t = s]\)</p> </blockquote> <blockquote> <p><strong>Definition</strong><br/> <em>action-value function</em><br/> \(q_\pi(s, a) = \mathbb{E}[G_t | S_t = s, A_t = a]\)</p> </blockquote> <h3 id="34-bellman-expectation-equation">3.4. Bellman Expectation Equation</h3> \[\begin{align*} v_\pi (s) &amp;= \mathbb{E}[G_t | S_t = s] \\ &amp;= \mathbb{E}[R_{t+1} + \gamma v_\pi(S_{t+1}) | S_t = s] \end{align*}\] \[\begin{align*} q_\pi(s, a) &amp;= \mathbb{E}[G_t | S_t = s, A_t = a] \\ &amp;= \mathbb{E}[R_{t+1} + \gamma q_\pi(S_{t+1}, A_{t+1}) | S_t = s, A_t = a] \end{align*}\] <p align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mdp/state-value-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mdp/state-value-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mdp/state-value-1400.webp"/> <img src="/assets/img/mdp/state-value.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </p> \[\begin{align*} v_\pi(s) = \sum_{a\in \mathcal{A}}{\pi(a|s)q_\pi(s, a)} \end{align*}\] <p align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mdp/action-value-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mdp/action-value-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mdp/action-value-1400.webp"/> <img src="/assets/img/mdp/action-value.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </p> \[\begin{align*} q_\pi(s, a) = \mathcal{R}_{s}^{a} + \gamma\sum_{s'\in \mathcal{S}}{\mathcal{P}_{ss'}^{a}v_\pi(s')} \end{align*}\] <p align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mdp/combine-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mdp/combine-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mdp/combine-1400.webp"/> <img src="/assets/img/mdp/combine.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </p> \[\begin{align*} v_\pi(s) = \sum_{a\in \mathcal{A}}{\pi(a|s) \left( \mathcal{R}_{s}^{a} + \gamma\sum_{s'\in \mathcal{S}}{\mathcal{P}_{ss'}^{a}v_\pi(s')} \right)} \end{align*}\]]]></content><author><name></name></author><category term="concepts"/><category term="RL"/><summary type="html"><![CDATA[MDP and MRP]]></summary></entry><entry><title type="html">Evidence Lower Bound (ELBO)</title><link href="https://3seoksw.github.io/blog/2023/ELBO/" rel="alternate" type="text/html" title="Evidence Lower Bound (ELBO)"/><published>2023-11-08T02:00:00+00:00</published><updated>2023-11-08T02:00:00+00:00</updated><id>https://3seoksw.github.io/blog/2023/ELBO</id><content type="html" xml:base="https://3seoksw.github.io/blog/2023/ELBO/"><![CDATA[<h1 id="elbo">ELBO</h1> <p>In <strong>Variational Bayesian Methods</strong>, the Evidence Lower Bound (<strong>ELBO</strong>) is a lower bound on the log-likelihood of some observed data.</p> <hr/> <h3 id="terminology-and-notation">Terminology and Notation</h3> <table> <tbody> <tr> <td>Let \(X\) and \(Z\) be random variables, jointly distributed with distribution \(p_\theta\). For example, \(p_\theta(X)\) is the <strong>Marginal Distribution</strong> of \(X\), and $$p_\theta(Z</td> <td>X)\(is the conditional distribution of\)Z\(given\)X\(. There, for any samle\)x \sim p_\theta\(, and any distribution\)q_\phi$$, we have</td> </tr> </tbody> </table> \[\ln{p_\theta}(x) \geq \mathbb{E}_{z\sim q_\phi}\left[\ln{\frac{p_\theta(x, z)}{q_\phi(z)}}\right].\] <p>LHS: <em>evidence</em> for \(x\) RHS: <em>evidence lower bound (ELBO)</em> for \(x\) The above is refered as the <em>ELBO inequality</em>.</p> <h3 id="applying">Applying</h3> <p>To derive the ELBO, we introduce <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen’s Inequality</a> applied to randam variables \(x \in X\) here:</p> \[\begin{align} f(\mathbb{E}[X]) \leq \mathbb{E}[f(X)] \end{align}\] <p>We apply <em>Jensen’s Inequality</em> to the \(\log\) (marginal) probability of the observations to get the ELBO.</p> \[\begin{align} \log p(x) &amp;= \log\int_z{p(x, z)dz} \\ &amp;= \log\int_z{p(x, z)\frac{q(z)}{q(z)}dz} \\ &amp;= \log\int_z{\frac{p(x, z)}{q(z)}q(z)dz} \\ &amp;= \log\left({\mathbb{E}_{q(z)}\left[ {\frac{p(x, z)}{q(z)}}\right]}\right) \\ &amp;\geq \mathbb{E}_{q(z)}\left[ \log{\frac{p(x, z)}{q(z)}} \right] \\ &amp;= \mathbb{E}_{q(z)}\left[ \log{p(x, z)} \right] - \mathbb{E}_{q(z)}[\log{q(z)}] \end{align}\] <p>All together, the ELBO for a probability model \(p(x, z)\) and an approximation \(q(z)\) to the posterior is: \(\mathbb{E}_{q(z)}[\log{p(x, z)}]-\mathbb{E}_{q(z)}[\log{q(z)}]\)</p>]]></content><author><name></name></author><category term="concepts"/><category term="statistics"/><category term="bayes"/><summary type="html"><![CDATA[a lower bound on the log-likelihood]]></summary></entry><entry><title type="html">Kullback-Leibler Divergence (KLD)</title><link href="https://3seoksw.github.io/blog/2023/KLD/" rel="alternate" type="text/html" title="Kullback-Leibler Divergence (KLD)"/><published>2023-11-08T02:00:00+00:00</published><updated>2023-11-08T02:00:00+00:00</updated><id>https://3seoksw.github.io/blog/2023/KLD</id><content type="html" xml:base="https://3seoksw.github.io/blog/2023/KLD/"><![CDATA[<h1 id="kullback-leibler-divergence">Kullback-Leibler Divergence</h1> <p>Kullback-Leibler Divergence is a type of statistical distance: a measure of how one probability distribution \(P\) is different (or similar) from the other probability distribution \(Q\).</p> <h3 id="notation">Notation</h3> \[\begin{align*} D_{KL}(P || Q) \\ KL(P || Q) \end{align*}\] <h3 id="defintion">Defintion</h3> <p>For discrete probability distributions \(P\) and \(Q\) defined on the same sample space \(\mathcal{X}\), the relative entropy from \(Q\) to \(P\) is defined to be \(KL(P || Q) = \sum_{x\in\mathcal{X}}P(x)\log{\frac{P(x)}{Q(x)}}\) For distributions \(P\) and \(Q\) of a continuous random variable, the relative entropy is defined to be \(KL(P || Q) = \int_{-\infty}^{+\infty}p(x)\log{\frac{p(x)}{q(x)}}dx\)</p> <h3 id="applying-kullback-leibler-divergence-to-bayesian-backpropagation">Applying Kullback-Leibler Divergence to Bayesian Backpropagation</h3> \[\begin{align*} \theta^{*} &amp;= \text{argmin}_{\theta}KL[q(w|\theta) \; || \; P(w|\mathcal{D})] \\ &amp;= \text{argmin}_{\theta}\int{q(w|\theta)\log{\frac{q(w|\theta)}{P(w|\mathcal{D})}}}dw \\ &amp;= \text{argmin}_{\theta}\int{q(w|\theta)\log{\frac{q(w|\theta)P(\mathcal{D})}{P(w)P(\mathcal{D}|w)}}}dw \\ &amp;= \text{argmin}_{\theta}\int{q(w|\theta)\log{\frac{q(w|\theta)}{P(w)P(\mathcal{D}|w)}}}dw \\ &amp;= \text{argmin}_{\theta}\left(\int{q(w|\theta)\log{\frac{q(w|\theta)}{P(w)}}}dw \; - \; \int{q(w|\mathcal{D})\log{P(\mathcal{D}|w)}dw} \right) \\ &amp;= KL[q(w|\theta) \; || \; P(w)] \; - \; \mathbb{E}_{q(w|\mathcal{D})}[\log{P(\mathcal{D}|w)}] \end{align*}\] <p>Complexity cost (prior-dependent part): \(KL[q(w \mid \theta) \mid \mid P(w)]\)</p> <p>Likelihood cost (data-dependent part): \(\mathbb{E}_{q(w \mid \mathcal{D})}[P(\mathcal{D}\mid w)]\)</p> <p>Resulting cost function:</p> \[\mathcal{F}(\mathcal{D}, \theta) = KL[q(w|\theta) || P(w)] - \mathbb{E}_{q(w|\mathcal{D})}[\log P(\mathcal{D}|w)]\]]]></content><author><name></name></author><category term="concepts"/><category term="statistics"/><category term="bayes"/><summary type="html"><![CDATA[statistical distance between two distributions]]></summary></entry><entry><title type="html">Cross-Entropy</title><link href="https://3seoksw.github.io/blog/2023/Cross-Entropy/" rel="alternate" type="text/html" title="Cross-Entropy"/><published>2023-11-01T01:30:00+00:00</published><updated>2023-11-01T01:30:00+00:00</updated><id>https://3seoksw.github.io/blog/2023/Cross-Entropy</id><content type="html" xml:base="https://3seoksw.github.io/blog/2023/Cross-Entropy/"><![CDATA[<p>The <strong>Cross-Entropy</strong> between two probability distributions \(p\) and \(q\) measures the difference for a given random variable or set of events.</p> <h3 id="definition">Definition</h3> <p>The <strong>Cross-entropy</strong> of the distribution \(q\) relative to a distribution \(p\) over a given set is defined as follows:</p> \[H(p, q) = -\mathbb{E}_p[\log q]\] <p>where \(\mathbb{E}_p[\cdot]\) is the expected value operator with respect to the distribution \(p\). The definition may be formulated using the <a href="https://3seoksw.github.io/blog/2023/KLD/">Kullback-Leibler Divergence</a> \(KL[p \mid\mid q]\).</p> \[H(p, q) = H(p) + KL[p \mid\mid q]\] <p>For discrete probability distributions:</p> \[H(P, Q) = -\sum_{x\in\mathcal{X}}p(x*i)\log{q(x_i)}\] <p>For continuous probability distributions:</p> \[H(p, q) = -\int_{\mathcal{X}}P(x)\log{Q(x)}dr(x)\]]]></content><author><name></name></author><category term="concepts"/><category term="statistics"/><category term="bayes"/><summary type="html"><![CDATA[A method to measure the difference between two different probability distributions]]></summary></entry><entry><title type="html">Maximum Likelihood Estimation (MLE)</title><link href="https://3seoksw.github.io/blog/2023/MLE/" rel="alternate" type="text/html" title="Maximum Likelihood Estimation (MLE)"/><published>2023-09-15T01:30:00+00:00</published><updated>2023-09-15T01:30:00+00:00</updated><id>https://3seoksw.github.io/blog/2023/MLE</id><content type="html" xml:base="https://3seoksw.github.io/blog/2023/MLE/"><![CDATA[<h1 id="maximum-likelihood-estimation-mle">Maximum Likelihood Estimation (MLE)</h1> <p>A maximum likelihood estimation (MLE) is a method of estimating the parameters of the given likelihood probability distribution.</p> <h3 id="definition">Definition</h3> <p>A value of \(\theta\) that maximizes \(L(\theta|x_1, x_2, ..., x_n)\). Most likely, natural log will be plugged (<a href="https://3seoksw.github.io/blog/2023/likelihood">Log-Likelihood Function</a>).</p> \[\begin{align*} \theta^* &amp;= \text{argmax}_\theta l(\theta|x_1, x_2, ..., x_n) \\ &amp;= \text{argmax}_\theta log(\mathcal{L}(\theta|x_1, x_2, ..., x_n)) \\ &amp;= \text{argmax}_\theta log(\prod_{i=1}^{n}f(x_i|\theta)) \\ &amp;= \text{argmax}_\theta log(f(x_1|\theta) \times f(x_2|\theta) \times ... \times f(x_n|\theta)) \\ &amp;= \text{argmax}_\theta \sum_{i=1}^{n}log(f(x_i|\theta)) \end{align*}\] <p>From <strong>Bayesian Backpropagation</strong>:</p> \[\begin{align*} w^\text{MLE} &amp;= \text{argmax}_wl(w|\mathcal{D}) \\ &amp;= \text{argmax}_w\log{\mathcal{L}(w|\mathcal{D})} \\ &amp;= \text{argmax}_w\log{P(\mathcal{D}|w)} \\ &amp;= \text{argmax}_w\log{P(\mathcal{D_1}, ...\mathcal{D_n}|w)} \\ &amp;= \text{argmax}_w\log{\prod_{i=1}^{n}P(\mathcal{D_i}|w)} \\ &amp;= \text{argmax}_w\sum_{i=1}^{n}{\log{P(\mathcal{D_i}|w)}} \\ &amp;= \text{argmax}_w\sum_{i=1}^{n}{\log{P(y_i|x_i,w)}} \\ \end{align*}\]]]></content><author><name></name></author><category term="concepts"/><category term="statistics"/><category term="bayes"/><summary type="html"><![CDATA[estimation method of a likelihood distribution]]></summary></entry><entry><title type="html">Bayes’ Theorem</title><link href="https://3seoksw.github.io/blog/2023/bayes-theorem/" rel="alternate" type="text/html" title="Bayes’ Theorem"/><published>2023-09-14T01:30:00+00:00</published><updated>2023-09-14T01:30:00+00:00</updated><id>https://3seoksw.github.io/blog/2023/bayes-theorem</id><content type="html" xml:base="https://3seoksw.github.io/blog/2023/bayes-theorem/"><![CDATA[<h1 id="bayes-theorem">Bayes’ Theorem</h1> <p><strong>Bayes’ Theorem</strong> (or Bayesian Theorem) is a statistical method to update our prior beliefs. Bayes theorem can be used in various fields such as in Machine Learning (ML) method.</p> <hr/> <h3 id="definition">Definition</h3> \[\begin{align*} \text{Posterior} \propto \text{Prior} \times \text{Likelihood} \\ P(A|B) = \frac{P(B|A) \times P(A)}{P(B)} \\ \end{align*}\] <h3 id="usage-in-ml">Usage in ML</h3> \[\begin{align*} P(w|\mathcal{D}) \propto P(\mathcal{D}|w) \times P(w) \\ \end{align*}\] <p>\(w\): Prior weights for a neural network<br/> \(\mathcal{D}\): Data<br/> \(P(w|\mathcal{D})\): Posterior distribution, a probability distribution of the neural network weights \(w\) after observing the data \(\mathcal{D}\)<br/> \(P(\mathcal{D}|w)\): Likelihood function, represents how well the neural network with parameters \(w\) fits the observed data \(\mathcal{D}\)<br/> \(P(w)\): Prior, prior beliefs about the neural network weights before observing the data \(\mathcal{D}\)<br/> \(P(y^*|x^*)=\mathbb{E}_{P(w|\mathcal{D})}[P(y^*|x^*, w)]\) At prediction time, the predictive distribution over the target \(y^*\) given a test input \(x^*\)<br/></p>]]></content><author><name></name></author><category term="concepts"/><category term="statistics"/><category term="bayes"/><summary type="html"><![CDATA[Bayes Rule, probability of an event based on prior knowledge]]></summary></entry></feed>
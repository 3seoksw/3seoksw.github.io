<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Dynaformer, A Deep Learning Model for Ageing-aware Battery Discharge Prediction | WooSeok Kim</title> <meta name="author" content="WooSeok Kim"> <meta name="description" content="Transformer-based Battery EoD Prediction Model"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://3seoksw.github.io/paper-reviews/Dynaformer-Review/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">WooSeok </span>Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/paper-reviews/">Paper Reviews</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Dynaformer, A Deep Learning Model for Ageing-aware Battery Discharge Prediction</h1> <p class="post-description">Transformer-based Battery EoD Prediction Model</p> </header> <article> <p>The review is done with the following paper:<br> <a href="https://www.sciencedirect.com/science/article/pii/S0306261923005937" rel="external nofollow noopener" target="_blank">Luca Biggio, Tommaso Bendinelli, Cheta Kulkarni, and Olga Fink. “Dynaformer: A Deep Learning Model for Ageing-aware Battery Discharge Prediction,” <em>Applied Energy</em>, 2023.</a></p> <h2 id="table-of-contents">Table of Contents</h2> <ul> <li><a href="#abstract">Abstract</a></li> <li> <a href="#background">Background</a> <ul> <li><a href="#battery">Battery</a></li> <li><a href="#transformer">Transformer</a></li> </ul> </li> <li> <a href="#model-architecture">Model Architecture</a> <ul> <li><a href="#embedding">Embedding</a></li> <li><a href="#encoder">Encoder</a></li> <li><a href="#decoder">Decoder</a></li> </ul> </li> <li> <a href="#results">Results</a> <ul> <li><a href="#experimental-setup">Experimental Setup</a></li> <li><a href="#performance-evaluation">Performance Evaluation</a></li> </ul> </li> <li><a href="#conclusion">Conclusion</a></li> </ul> <h2 id="abstract">Abstract</h2> <p>The main purpose of the paper is to propose a novel deep learning architecture which can be applied to batteries, namely <strong>Dynaformer</strong>. The model, Dynaformer, is a Transformer-based <a href="#2">[2]</a> model and outputs an EoD (end of discharge) prediction, given some context current and voltage curves.</p> <p>Dynaformer is able to infer the ageing state from a limited samples and predict the full voltage discharge curve, EoD, simultaneously.</p> <h2 id="background">Background</h2> <h3 id="battery">Battery</h3> <p>The following <em>Figure 1.</em> represents how batteries’ voltage curves look like based on the given input current profiles. When given constant current, it forms a continuous curve as the graph on the far left. On the other hand, when given some variable current profiles with multiple transitions, the graphs differ from the other corresponding to the altering current.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig1-1400.webp"></source> <img src="/assets/img/dynaformer/fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p align="center"> <i>Figure 1.</i> Varying voltage curves corresponding to altering current profiles <a href="#1">[1]</a> </p> <p>There are two main categories of solving EoD prediction and ageing inference: model-based method and data-driven method. The first method, model-based method, mainly focuses on representation of battery’s physical internal mechanism. By constructing an ideal model of the battery, it has a good performance. However, due to it’s complex representation of the model, it is computationally expensive and is not an easy work to design the model precisely.<br> The second method, data-driven method, is to predict EoD and ageing inference using a huge amount of battery data. It is easier to model the system compared to the model-based method since it requires minimum prior knowledge on the battery’s discharge and degradation processes. Nevertheless, it also has some disadvantages. It requires large labeled training dataset and it is inefficient to train with such long time series data.</p> <h3 id="transformer">Transformer</h3> <p>It is essential to understand how <strong>Transformer</strong> <a href="#2">[2]</a> works in order to understand the Dynaformer. Let’s consider the following sentence.</p> <p align="center"> <b>The dog</b> is playing and <b>she</b> likes playing with <b>me</b>. </p> <p>We know that <b>she</b> is indicating <b>the dog</b>, not <b>me</b>. Transformer is all about understanding the context and the hidden meaning behind the given data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig2-1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig2-1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig2-1-1400.webp"></source> <img src="/assets/img/dynaformer/fig2-1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig2-2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig2-2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig2-2-1400.webp"></source> <img src="/assets/img/dynaformer/fig2-2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig2-3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig2-3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig2-3-1400.webp"></source> <img src="/assets/img/dynaformer/fig2-3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p align="center"> <i>Figure 2.</i> Transformer model architecture <a href="#2">[2]</a>. (Left) Positional embedding (Centre) Encoder (Right) Decoder </p> <p>Transformer is consists of three major parts: positional embedding, encoder and decoder. The above <em>Figure 2.</em> represents the mentioned three parts.<br> Positional embedding is to transfer the given data into numerical vectors. By doing so, positional information can be embedded within the vectors.<br></p> <p>Encoder’s job is to obtain <strong>query</strong>, <strong>key</strong> and <strong>value</strong> – \((Q, K, V)\) – given some positional embedding. The <strong>query</strong> is a vector which contains given specific data such as a word itself when a sentence is given. The <strong>key</strong> is a value which can specify the <strong>query</strong>. And lastly, the <strong>value</strong> represents the <strong>query</strong>’s hidden meaning. It can contain context or positional information. Here, <strong>self-attention</strong> comes in. Simply saying, self-attention cells find the correlations among the data by using \((Q, K, V)\).<br></p> <p>Decoder’s job is very similiar with the encoder but it differs with the main purpose. While the encoder’s main purpose is to find the correlations among input data, the decoder’s main purpose is to find the correlations between the input data and ouput data.<br> To simplify, let’s bring the classic translation example. Say I want to translate some English sentences into Korean sentences. Then the input of the encoder is the English sentences and the input of the decoder is the the Korean sentences, in other words, data that we target. So the encoder mainly interprets and finds the meaning, hidden information, and correlations from the English sentences, and the decoder focuses on finding the correlations between the English sentences and the Korean sentences, when training.<br> Back to the point, the decoder also obtains <strong>query</strong>, <strong>key</strong>, and <strong>value</strong>. However, in the decoder, <strong>key</strong> and <strong>value</strong> from the encoder and <strong>query</strong> from decoder will only be used. By using \((K, V)\) from the encoder and \((Q)\) from the decoder, the decoder is able to apply self-attention mechanism to find the correlations between the data we want to interpret and the data we aims.</p> <h2 id="model-architecture">Model Architecture</h2> <div align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig2-3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig2-3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig2-3-1400.webp"></source> <img src="/assets/img/dynaformer/fig2-3.png" class="img-fluid rounded z-depth-1" width="75%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p align="center"> <i>Figure 3.</i> Representation of the components of Dynaformer <a href="#1">[1]</a> </p> <p>The proposed Dynaformer is basically the same with the Transformer model but with the difference of the data type. Since the paper is to predict EoD, input data types are current and voltage curves. Note that the inputs of the encoder are current and voltage curves and the inputs of the decoder are the rest of the current curves and the output of the encoder, then eventually outputs full discharge voltage curves.</p> <div align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig4-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig4-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig4-1400.webp"></source> <img src="/assets/img/dynaformer/fig4.jpg" class="img-fluid rounded z-depth-1" width="75%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p align="center"> <i>Figure 4.</i> Dynaformer - model architecture <a href="#1">[1]</a> </p> <p><em>Figure 3.</em> and <em>Figure 4.</em> are the same model architecture, but for the sake of easy understanding of the Dynaformer using the Transformer-style architecture representation, <em>Figure 3.</em> can be redrawn as <em>Figure 4.</em>. The following figures specify each part from the Dynaformer.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig4-1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig4-1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig4-1-1400.webp"></source> <img src="/assets/img/dynaformer/fig4-1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig4-2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig4-2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig4-2-1400.webp"></source> <img src="/assets/img/dynaformer/fig4-2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig4-3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig4-3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig4-3-1400.webp"></source> <img src="/assets/img/dynaformer/fig4-3.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p align="center"> <i>Figure 4-1, 4-2, 4-3.</i> Dynaformer - detailed model architecture <a href="#1">[1]</a>. (Left) Positional embedding (Centre) Encoder (Right) Decoder </p> <h3 id="embedding">Embedding</h3> <div align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig5-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig5-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig5-1400.webp"></source> <img src="/assets/img/dynaformer/fig5.jpg" class="img-fluid rounded z-depth-1" width="75%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p align="center"> <i>Figure 5.</i> Dynaformer - (Context) Embedding <a href="#1">[1]</a> </p> <p>Here, Dynaformer gets information regarding the battery’s profiles, which are current profile (curve) and voltage profile (curve). While (positional) embedding, nothing special happens but reshapes the data into \((Q, K, V)\) including positional, context information. The \(Q\) represents current and voltage curves, the \(K\) serves as a specifier to find the \(Q\), and the \(V\) contains positional information such as time for the matching \(Q\).</p> <h3 id="encoder">Encoder</h3> <div align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig6-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig6-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig6-1400.webp"></source> <img src="/assets/img/dynaformer/fig6.jpg" class="img-fluid rounded z-depth-1" width="75%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p align="center"> <i>Figure 6.</i> Dynaformer - Encoder </p> <p>The encoder’s inputs are \((Q, K, V)\) from the embedding. Here, it’s main role is to find the correlations between the input current, voltage, and time which will eventually extracts degradation information. In order to find such information, multi-head self-attention cells are used. For further information regarding self-attention mechanism, please see <a href="#2">[2]</a>.</p> <h3 id="decoder">Decoder</h3> <div align="center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/dynaformer/fig7-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/dynaformer/fig7-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/dynaformer/fig7-1400.webp"></source> <img src="/assets/img/dynaformer/fig7.jpg" class="img-fluid rounded z-depth-1" width="75%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p align="center"> <i>Figure 7.</i> Dynaformer - Decoder <a href="#1">[1]</a> </p> <p>The decoder predicts EoD as a final ouput, given the ageing inference from the encoder’s ouput and the rest of the current curves which are from the decoder’s input. Using the ageing inference, \((K, V)\), and the rest of the current curves, \(Q\), the Dynaformer is now able to predict the voltage curves corresponding to the current curves from the input of the decoder exploiting the ageing inference information from the encoder.</p> <h2 id="results">Results</h2> <h3 id="experimental-setup">Experimental Setup</h3> <p>Just like I’ve mentioned from the <a href="#battery">Background - Battery</a> section, there are two main limitations when using data-driven method for predicting EoD and ageing inference: requires large labeled dataset and requires long time series dataset which is inefficient for training.<br> The proposed Dynaformer solves the problems originally had when using data-driven method.</p> <p>First, the Dynaformer mitigated the problem of lack of dataset for training by using the following: <a href="#3">[3]</a> and <a href="#4">[4]</a>. <a href="#3">[3]</a> is a NASA Prognostics Model library which helps creating a simulated training dataset. The paper experiments the model by changing two degradation parameters, \(q_max\) and \(R_0\), to observe the performance change when the parameters changed. Also <a href="#4">[4]</a> is a NASA real-world Dataset for batteries and is used as a input for the simulator, <a href="#3">[3]</a>.<br> However, there may be a simulation-to-real gap (sim2real gap) since the training dataset is a simulation-based data. To mitigate such concern, the paper applied transfer learning. As <a href="#5">[5]</a> suggests, training the model with simulated data then using a limited amount of real data to adapt the model can reduce the model’s bias towards simulated data.</p> <p>Second, the Dynaformer gets the <strong>tokenized</strong> input. In other words, instead of feeding a full length of the curves, the Dynaformer only accepts a small sized curves in sequence. Please see <em>Figure 3.</em> for better understanding of the concept of <strong>token</strong>. Training the model with long time series data is in fact inefficient. However, using the technique from <a href="#6">[6]</a> solves such problem.</p> <h3 id="performance-evaluation">Performance Evaluation</h3> <h2 id="conclusion">Conclusion</h2> <h2 id="reference">Reference</h2> <p><a id="1" href="https://www.sciencedirect.com/science/article/pii/S0306261923005937" rel="external nofollow noopener" target="_blank">[1]</a> Luca Biggio, Tommaso Bendinelli, Cheta Kulkarni, and Olga Fink. “Dynaformer: A Deep Learning Model for Ageing-aware Battery Discharge Prediction,” <i> <em>Applied Energy</em></i> 2023.</p> <p><a id="2" href="https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" rel="external nofollow noopener" target="_blank">[2]</a> Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention is All you Need,” <i>Advances in Neural Information Processing Systems 30 (NIPS 2017)</i>, 2017.</p> <p><a id="3" href="https://nasa.github.io/progpy/index.html" rel="external nofollow noopener" target="_blank">[3]</a> Chris Teubert, Katelyn Jarvis, Matteo Corbetta, Chetan Kulkarni, Portia Banerjee, Jason Watkins, and Matthew Daigle, “ProgPy Python Prognostics Packages,” v1.6, Oct 2023. URL <a href="https://nasa.github.io/progpy/index.html" rel="external nofollow noopener" target="_blank">https://nasa.github.io/progpy/index.html</a></p> <p><a id="4" href="https://www.nasa.gov/intelligent-systems-division/discovery-and-systems-health/pcoe/pcoe-data-set-repository/" rel="external nofollow noopener" target="_blank">[4]</a> B. Saha and K. Goebel (2007). “Battery Data Set”, NASA Prognostics Data Repository, NASA Ames Research Center, Moffett Field, CA.</p> <p><a id="5" href="https://link.springer.com/chapter/10.1007/978-3-030-32381-3_16" rel="external nofollow noopener" target="_blank">[5]</a> Sun, Chi, Xipeng Qiu, Yige Xu, and Xuanjing Huang. “How to fine-tune bert for text classification?.” In <i>Chinese Computational Linguistics: 18th China National Conference, CCL 2019, Kunming, China, October 18–20, 2019, Proceedings 18</i>, pp. 194-206. Springer International Publishing, 2019.</p> <p><a id="6" href="https://arxiv.org/abs/2010.11929" rel="external nofollow noopener" target="_blank">[6]</a> Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani et al. “An image is worth 16x16 words: Transformers for image recognition at scale.” <i>arXiv preprint arXiv:2010.11929</i> (2020).</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/dynaformer-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/dynaformer-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/dynaformer-1400.webp"></source> <img src="/assets/img/publication_preview/dynaformer.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="dynaformer.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="biggio2022dynaformer" class="col-sm-8"> <div class="title">Dynaformer: A Deep Learning Model for Ageing-aware Battery Discharge Prediction</div> <div class="author"> Luca Biggio, Tommaso Bendinelli, Chetan Kulkarni, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Olga Fink' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 WooSeok Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>